{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumyadip-Ghosh-18/Soumyadip-Ghosh-18/blob/main/Soumyadip_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0: Install dependencies"
      ],
      "metadata": {
        "id": "K3yWWtQ8cC4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 langgraph langchain langchain-google-genai openai"
      ],
      "metadata": {
        "id": "4oNn_0DcBlHH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Imports and secure API key input"
      ],
      "metadata": {
        "id": "XvoFPl11cFhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "# getpass used to get password for api to work & nobody can view the api.\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n"
      ],
      "metadata": {
        "id": "gpJuqPy8CsVX"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Secure Gemini API Key input"
      ],
      "metadata": {
        "id": "W28u20SxcIiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OVR5rNIFDL--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = getpass.getpass(\"Enter the Gemini API Key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHSQnMtZC7_2",
        "outputId": "987ff779-718f-4800-9f9c-4424179a6d40"
      },
      "execution_count": 53,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the Gemini API Key··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Initialize Gemini 1.5 Flash"
      ],
      "metadata": {
        "id": "eusINPuVcLXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model = \"models/gemini-1.5-flash-latest\", temperature =0.5)\n",
        "# temperature -> How much varities of answers are needed."
      ],
      "metadata": {
        "id": "_5yTs0T86i2J"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Node to ask user for symptom"
      ],
      "metadata": {
        "id": "o07zbkLWcOVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_symptom(state: dict) -> dict:\n",
        "  symptom = input(\"Welcome to Apolo Hospitals: Enter your symptom.\\n\")\n",
        "  state[\"symptom\"] = symptom\n",
        "  return state"
      ],
      "metadata": {
        "id": "IjIoJAGk9WOt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Node to classify the symptom"
      ],
      "metadata": {
        "id": "0KIzyYPVcRVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_symptom(state: dict) -> dict:\n",
        "  prompt = (\"You are a medical assistent in some hospital and your task is to classify symptoms in one of the following catagories. \\n\"\n",
        "  \"General\\n -Emergency\\n -Serious \\n\"\n",
        "  f\"Symptom : {state['symptom']} \\n\"\n",
        "  \"Respond in one word: General, Emergency, Serious \\n\"\n",
        "  \"#Example : input : I have fever, Output : General\"\n",
        "  )\n",
        "  response = llm.invoke([HumanMessage(content = prompt)])\n",
        "  catagory = response.content.strip()\n",
        "  print(\"LLM identifies the symptom as\", catagory)\n",
        "  state[\"catagory\"] = catagory\n",
        "  return state\n"
      ],
      "metadata": {
        "id": "n95CJ5naGrUj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Router logic to route to the correct node\n"
      ],
      "metadata": {
        "id": "kESmxbnicWpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symptom_router(state: dict) -> dict:\n",
        "  cat = state['catagory'].lower()\n",
        "  if cat == 'general':\n",
        "    return 'general'\n",
        "  elif cat == 'emergency':\n",
        "    return 'emergency'\n",
        "  elif cat == 'serious':\n",
        "    return 'serious'\n",
        "  else:\n",
        "    return 'critical'"
      ],
      "metadata": {
        "id": "hBnpi7F-LQyr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6: Category-specific response nodes\n"
      ],
      "metadata": {
        "id": "cZuR4VGscake"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def general_node(state: dict) -> dict:\n",
        "  state['answer'] = f\"'{state['symptom']}': Seems like a General case: reffering to General Ward, consult a doctor in there.\"\n",
        "  return state\n",
        "def emergency_node(state: dict) -> dict:\n",
        "  state['answer'] = f\"'{state['symptom']}': It is an Emergency case: Urgent treatment needed: reffering to Emergency Ward.\"\n",
        "  return state\n",
        "def serious_node(state: dict) -> dict:\n",
        "  state['answer'] = f\"'{state['symptom']}': Seems like it is a Serious case: admiting you, booking a doctor specifically for you.\"\n",
        "  return state\n",
        "def critical_node(state: dict) -> dict:\n",
        "  state['answer'] = f\"'{state['symptom']}': It is a Critical case: get admission as early as possible, now I am booking a meeting with specilized doctor.\"\n",
        "  return state"
      ],
      "metadata": {
        "id": "di60bBd0MLdM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 7: Build LangGraph\n"
      ],
      "metadata": {
        "id": "I1ek0SwzcehS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(dict)\n",
        "\n",
        "#define the nodes\n",
        "builder.set_entry_point(\"get_symptom\")\n",
        "builder.add_node(\"get_symptom\", get_symptom)\n",
        "builder.add_node(\"classify\", classify_symptom)\n",
        "builder.add_node(\"general\", general_node)\n",
        "builder.add_node(\"emergency\", emergency_node)\n",
        "builder.add_node(\"serious\", serious_node)\n",
        "builder.add_node(\"critical\", critical_node)\n",
        "\n",
        "builder.add_edge(\"get_symptom\", \"classify\")\n",
        "builder.add_conditional_edges(\"classify\", symptom_router, {\n",
        "    \"general\": \"general\",\n",
        "    \"emergency\": \"emergency\",\n",
        "    \"serious\": \"serious\"\n",
        "})\n",
        "\n",
        "builder.add_edge(\"general\", END)\n",
        "builder.add_edge(\"emergency\", END)\n",
        "builder.add_edge(\"serious\", END)\n",
        "builder.add_edge(\"critical\", END)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob9GlIa7Rk5w",
        "outputId": "e178c3ea-7a77-43db-99df-8124f624650c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7c9eacb7edd0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 8: Compile and invoke the graph\n"
      ],
      "metadata": {
        "id": "GbAgCeZYci5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "-nD62FxiTAPe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_state = graph.invoke({})\n",
        "print(\"Final Output \\n\")\n",
        "print(final_state['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S478zjq-TG8i",
        "outputId": "24147bcf-f400-41de-98e9-1fe0234a42dd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Apolo Hospitals: Enter your symptom.\n",
            "I am feeling very little pain in my full body, and facing lower energy levels while doing any work.\n",
            "LLM identifies the symptom as General\n",
            "Final Output \n",
            "\n",
            "'I am feeling very little pain in my full body, and facing lower energy levels while doing any work.': Seems like a General case: reffering to General Ward, consult a doctor in there.\n"
          ]
        }
      ]
    }
  ]
}